# Customer Churn Monitoring with Data Drift Detection

This project demonstrates an end-to-end machine learning workflow:  
model training, simulated production data drift, statistical drift detection, and automated model risk assessment.

---

## ğŸ” Project Overview

The goal is not only to predict customer churn, but to monitor whether the data environment changes over time and whether such changes impact model behavior.

The system:
- Trains a churn prediction model
- Simulates real-world data drift
- Detects feature-level data drift statistically
- Measures prediction shift
- Produces an automated **MODEL_OK / MODEL_AT_RISK** decision

---

## ğŸ“ Structure

```
customer-churn-drift/
â”‚
â”œâ”€â”€ model_training.ipynb
â”œâ”€â”€ data_drift_simulation.ipynb
â”œâ”€â”€ model_monitoring.ipynb
â”‚
â”œâ”€â”€ data/
â”œâ”€â”€ models/
â”œâ”€â”€ reports/
â”œâ”€â”€ requierments.txt
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run

=>Firstly, get all the requirements:
```bash
pip install -r requirements.txt
```

1. Train the model:
```bash
python model_training.ipynb
```

2. Simulate data drift:
```bash
python data_drift_simulation.ipynb
```

3. Run monitoring:
```bash
python model_monitoring.ipynb
```

This generates:
- `reports/monitoring_summary.csv`
- `reports/feature_drift_report.csv`

---

## ğŸ§  Key Concepts Demonstrated

- Data drift detection (KS test, Chi-square)
- Prediction shift analysis
- Threshold-based model risk alerts
- Reusable monitoring pipeline

---

## ğŸ“Œ Outcome

The system automatically determines whether the deployed model is still reliable based on both data distribution changes and their impact on predictions.

---

## ğŸ‘¨â€ğŸ’» Author

Built as a portfolio project to demonstrate production-style machine learning monitoring and MLOps fundamentals.
